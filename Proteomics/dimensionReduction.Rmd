Dimension reduction
========================================================

Dimension reduction is a way to find patterns inside data, when their dimension is too important to be studied directly.

The aim is to find a set of uncorrelated variables that can explain as much of the observed variance as possible.

From another point of view, original data can be equivalent to another matrix made up of fewer variables, with more or less loss of details. This technique is common in image manipulation, especially in image compression. 


Singular Value Decomposition (SVD)
--------------------------------------------------------------------------------


```{r, echo=FALSE}
## For this paragraph we will use the iris data set.
data(iris)
## Only numerical values (we don't use Species, only the measurements)
irisVals <- iris[,1:4]
```

### Decomposition

SVD can be easily run with the svd() function.

NB: As it cannot be performed when missing values are present, it may be interesting to perform data imputation beforehand.

```{r}
svdIris <- svd(scale(irisVals))
```

The function outputs three elements, a vector d, and two matrices u and v.
- D contains the singular values ordered by decreasing size
- U and V can be combined with D to re-create the original input matrix. U has the same number of columns as the original data, and V has the same number of columns as the number of rows in the original data.

```{r}
dVector <-  svdIris$d
uMatrix <- svdIris$u
vMatrix <- svdIris$v
```

### Explained variance

From these values, one can plot the percentage of explained variance through each of the singular values.

```{r}
percentVarianceExplained <- dVector^2/sum(dVector^2)
plot(percentVarianceExplained, type="b")
```

Plot of the first two columns of the U matrix, showing how each row of the original data contributes to the global variance.

```{r}
plot(uMatrix[,1], pch=16, col=factor(iris$Species))
legend(x=3.2, y=0.15, legend=unique(iris$Species), pch=16, col=1:4)
```

Plot of the first two columns of the V matrix, showing how each row of the original data contributes to the global variance.

```{r}
plot(vMatrix[,1], pch=16, col=1:4)
legend(x=3.2, y=0, legend=names(irisVals), pch=16, col=1:4)
```

### Reconstructing data

From the decompositon, we can recreate the original data using the formula U * diag(D) * t(V).
```{r}
reconstructedData <- uMatrix %*% diag(dVector) %*% t(vMatrix)
sum(scale(irisVals) - reconstructedData)
```

To compress the volume of data, we can also focus only on the first singular values (see paragraph "Decomposing/compressing image data").


### Clustering improvement

An interesting usage of this method is combined with a clustering method. SVD can help focusing on the parts of the data with the most variance, and by removing noise, making the clustering more efficient.

For this paragraph we will use the iris data set. 

```{r, echo=FALSE}
data(iris)
## Only numerical values (we don't use Species, only the measurements)
irisVals <- iris[,1:4]
```

For a beginning, just remember what we can obtain with hierarchical clustering of all the dataset. Black group is in its own sub-cluster, but red is split between the two first binary branches.

```{r, echo=FALSE}
distances <- as.matrix(dist(irisVals, method="euclidean"))
hclustTree <- hclust(as.dist(distances))
colorLabels <- factor(iris$Species)
dendrogramH <- as.dendrogram(hclustTree)
dendColored <- dendrapply(dendrogramH, FUN=function(n) {
    if(is.leaf(n)) {
        att <- attributes(n)
        attr(n, "nodePar") <- c(
            att$nodePar,
            list(lab.col = as.numeric(colorLabels[as.numeric(att$label)]), 
                 lab.cex=.7, cex=NA, pch=16 )
            )
    }
    return(n)
})
plot(dendColored, pch=NA)
```

We can apply SVD on this dataset.

```{r, echo=FALSE}
svdIris <- svd(scale(irisVals))
dVector <-  svdIris$d
uMatrix <- svdIris$u
vMatrix <- svdIris$v
```

And we can plot the different singular values.

First, we can plot columns of the U matrix, showing how each row of the original data contributes to the global variance. First column already allows to differentiate rather well the three different species. Second column, Species are not well separated. Third column shows a different trend for the first and last species, compared to the second.

```{r, echo=FALSE}
layout(matrix(c(1:4), nrow=2, byrow=TRUE))
plot(uMatrix[,1], pch=16, col=factor(iris$Species), main="1")
legend(x=3.2, y=0.15, legend=unique(iris$Species), pch=16, col=1:3, cex=0.7)
plot(uMatrix[,2], pch=16, col=factor(iris$Species), main="2")
plot(uMatrix[,3], pch=16, col=factor(iris$Species), main="3")
plot(uMatrix[,4], pch=16, col=factor(iris$Species), main="4")
```

We can use the output of the SVD in order to improve the clustering by keeping only levels of interest to reconstruct the data.

```{r, echo=FALSE}
compressedData <- as.matrix(uMatrix[,1]) %*% diag(as.matrix(dVector[1])) %*% t(vMatrix[,1])
distances <- as.matrix(dist(compressedData, method="euclidean"))
hclustTree <- hclust(as.dist(distances))
colorLabels <- factor(iris$Species)
dendrogramH <- as.dendrogram(hclustTree)
dendColored <- dendrapply(dendrogramH, FUN=function(n) {
    if(is.leaf(n)) {
        att <- attributes(n)
        attr(n, "nodePar") <- c(
            att$nodePar,
            list(lab.col = as.numeric(colorLabels[as.numeric(att$label)]), 
                 lab.cex=.7, cex=NA, pch=16 )
            )
    }
    return(n)
})
plot(dendColored, pch=NA)
```

Plot of the columns of the V matrix, showing how each column of the original data contributes to the global variance.  First column shows that Sepal.width participates less, and Petal.Length the most.

```{r, echo=FALSE}
layout(matrix(c(1:4), nrow=2, byrow=TRUE))
plot(vMatrix[,1], pch=16, col=1:4, main="1")
legend(x=3.2, y=0, legend=names(irisVals), pch=16, col=1:4, cex=0.7)
plot(vMatrix[,2], pch=16, col=1:4, main="2")
plot(vMatrix[,3], pch=16, col=1:4, main="3")
plot(vMatrix[,4], pch=16, col=1:4, main="4")
```

We can also focus on Petal.Length only, as we saw that in the first column of the V matrix, this column of data had the most influence.

```{r, echo=FALSE}
svdIris2 <- svd(scale(irisVals[, c("Petal.Length")]))
compressedData2 <- as.matrix(svdIris2$u[,1]) %*% diag(as.matrix(svdIris2$d[1])) %*% t(svdIris2$v[,1])
distances2 <- as.matrix(dist(compressedData2, method="euclidean"))
hclustTree2 <- hclust(as.dist(distances2))
colorLabels2 <- factor(iris$Species)
dendrogramH2 <- as.dendrogram(hclustTree2)
dendColored2 <- dendrapply(dendrogramH2, FUN=function(n) {
    if(is.leaf(n)) {
        att <- attributes(n)
        attr(n, "nodePar") <- c(
            att$nodePar,
            list(lab.col = as.numeric(colorLabels2[as.numeric(att$label)]), 
                 lab.cex=.7, cex=NA, pch=16 )
            )
    }
    return(n)
})
plot(dendColored2, pch=NA)
```


### Decomposing/compressing image data

This technique can also be applied to image compression.

```{r}
## For this paragraph we will use the volcano data, from topographic 
## information on Auckland's Maunga Whau Volcano. As this is topographic data, 
## no need to scale it.
data(volcano)
image(volcano)
svdVolcanoImg <- svd(volcano)
dVector <-  svdVolcanoImg$d
uMatrix <- svdVolcanoImg$u
vMatrix <- svdVolcanoImg$v
```

A reconstruction of the original input image.
```{r}
reconstructedImg <- uMatrix %*% diag(dVector) %*% t(vMatrix)
image(reconstructedImg)
```

A compressed version of the original matrix using the first singular values (containing most of the information).
```{r}
compressedImg <- as.matrix(uMatrix[,1]) %*% diag(as.matrix(dVector[1])) %*% t(vMatrix[,1])
image(compressedImg)
```

A compressed version of the original matrix using the first three singular values.

```{r}
compressedImg <- uMatrix[,1:3] %*% diag(dVector[1:3]) %*% t(vMatrix[,1:3])
image(compressedImg)
```


--------------------------------------------------------------------------------

Principal component analysis
--------------------------------------------------------------------------------

Principal component analysis tries to change the coordinate system of the data (new set of vectors) in order to maximize the variance along each new vector. First component gathers the maximal explained variance. The second is perpendicular to the first and gathers the maximum of the remaining variance. And so on, all vectors being mutually perpendicular.
As the space of the dataset depends on its number of columns, the new coordinate system will have as many vectors as the number of columns in the dataset.

```{r}
##For this paragraph we will use the iris data set.
data(iris)
## Only numerical values (we don't use Species, only the measurements)
irisVals <- iris[,1:4]
```

### princomp()

PCA can be run with the princomp() function from the base package. 
From the help page (R version 2.15.2 (2012-10-26)):
> The calculation is done using eigen() on the correlation or covariance 
> matrix, as determined by cor(). This is done for compatibility with the 
> S-PLUS result. A preferred method of calculation is to use svd() on x, as 
> is done in prcomp().

The princomp() function is numerically less stable than prcomp() which is a better alternative. However, its output structure differs somewhat from that for princomp(). 

```{r}
pcaOutput <- princomp(irisVals, cor=TRUE)
```

Vizualisation of the explained variance by component using a Scree Plot. As explained, first component get most of the variance.
```{r}
screeplot(pcaOutput, type="lines")
```

More precisely, plot of the percentages of variance explained by each component.

```{r}
plot(x=(pcaOutput$sdev^2 / sum(pcaOutput$sdev^2)), type="b", ylab="% Variance explained")
```

Plot of the projections of the data points along the first two principal components. Coordinates are stored in the 'scores' slot of the output object (pcaOutput$scores). 

```{r}
plot(pcaOutput$scores[, c(1,2)], pch=16)
```

Biplot representing both the Respondent (samples, observations) and Questions (characteristics to be observed)

```{r}
## Iris data
## Questions = Sepal.width, Sepal.length, Petal.width, Petal.length
## Respondents = Flower measurements
biplot(pcaOutput, cex=0.7, pc.biplot=TRUE, choices=c(1,2))
```

Miscellaneous information can be accessed with summary().

```{r}
## Print "Standard deviation", "Proportion of Variance" and "Cumulative Proportion"
summary(pcaOutput)
```


### prcomp()

From the help page (R version 2.15.2 (2012-10-26)):
> The calculation is done by a singular value decomposition of the (centered 
> and possibly scaled) data matrix, not by using eigen on the covariance 
> matrix. This is generally the preferred method for numerical accuracy.


```{r}
prcOutput <- prcomp(irisVals, cor=TRUE)
```

"Standard deviation", "Proportion of Variance" and "Cumulative Proportion" can be accessed with summary().
```{r}
summary(prcOutput)
```

Vizualisation of the explained variance by component using a Scree Plot.
```{r}
screeplot(prcOutput, type="lines")
```

Plot of the projections of the data points along the first two principal components. Coordinates are stored in the 'x' slot of the output object (prcOutput$x). 
```{r}
plot(prcOutput$x[, 1:2], pch=16)
```

Biplot representing both the Respondent (samples, observations) and Questions (characteristics to be observed)
```{r}
## Iris data
## Questions = Sepal.width, Sepal.length, Petal.width, Petal.length
## Respondents = Flower measurements
biplot(prcOutput, cex=0.7, pc.biplot=TRUE)
```



--------------------------------------------------------------------------------

Factor analysis
--------------------------------------------------------------------------------

Exploratory method. See http://www.statmethods.net/advstats/factor.html

--------------------------------------------------------------------------------
Alternatives: 
- Independent component analysis
- Latent semantic analysis

See also: http://manuals.bioinformatics.ucr.edu/home/R_BioCondManual

<a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-sa/3.0/80x15.png" /></a><br />This work by <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName">Celine Hernandez</span> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US">Creative Commons Attribution-ShareAlike 3.0 Unported License</a>.